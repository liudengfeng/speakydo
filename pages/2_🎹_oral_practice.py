import streamlit as st
import streamlit.components.v1 as components
from pylib.cognitive import (
    # speech_recognize_once_from_mic,
    speech_synthesis_to_file,
    # record_audio,
    pronunciation_assessment_from_microphone,
)
from pylib.constants import TTS_VOICES
from pathlib import Path
from annotated_text import annotated_text, annotation

# --- PATH SETTINGS ---
current_dir: Path = Path(__file__).parent.parent

voice_path: Path = current_dir / "static/audio"

st.set_page_config(
    page_title="å£è¯­ç»ƒä¹ ",
    page_icon="ğŸ—£ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ç»ƒä¹ å£è¯­å†å²è®°å½•
if "spoken_list" not in st.session_state:
    st.session_state["spoken_list"] = []

# ä¾§é¢èœå•æ³¨é‡Š
st.sidebar.subheader(st.session_state.native_language.oral_practice_label)

voice_options = [
    item[0] for item in TTS_VOICES[st.session_state.target_language.language_key]
]


def get_index(voice):
    names = [
        item[0] for item in TTS_VOICES[st.session_state.target_language.language_key]
    ]
    return names.index(voice)


def voice_format_func(voice):
    i = get_index(voice)
    return TTS_VOICES[st.session_state.target_language.language_key][i][1]


st.sidebar.selectbox(
    st.session_state.native_language.selectbox_voice_name_label,
    voice_options,
    format_func=voice_format_func,
    key="voice_name",
    # label_visibility="hidden",
)


voice_file = voice_path / "{}.wav".format(st.session_state["voice_name"])
st.sidebar.audio(str(voice_file))

# æŒ‡å®šå½•åˆ¶éŸ³é¢‘æ—¶é•¿
max_duration = st.sidebar.slider(
    st.session_state.native_language.voice_duration_label,
    min_value=3,
    max_value=30,
    value=15,
)  # Duration of recording


@st.cache_data(show_spinner="Speech synthesis from Azure AI...")
def tts_mav_file(text):
    return speech_synthesis_to_file(
        text,
        st.session_state["voice_name"],
        st.secrets.Microsoft.SPEECH_KEY,
        st.secrets.Microsoft.SPEECH_REGION,
    )


@st.cache_data(
    show_spinner="Performs one-shot pronunciation assessment asynchronously with input from microphone with Azure AI..."
)
def pafm(text):
    return pronunciation_assessment_from_microphone(
        text,
        st.secrets.Microsoft.SPEECH_KEY,
        st.secrets.Microsoft.SPEECH_REGION,
        st.session_state.target_language.language_key,
    )


def gen_badge(mispronunciation, omission, insertion):
    return f"""
    <button type="button" class="btn btn-warning" data-bs-toggle="tooltip" data-bs-placement="top" data-bs-title="è¯´å¾—ä¸æ­£ç¡®çš„å­—è¯ã€‚æ­¤ç±»å‹æ¥è‡ª SDK è¿”å›çš„å‚æ•°: "ErrorType"ã€‚">
    å‘éŸ³é”™è¯¯
    <span class="badge text-bg-warning">{mispronunciation}</span>
    </button>
    <button type="button" class="btn btn-secondary" data-bs-toggle="tooltip" data-bs-placement="top" data-bs-title="è„šæœ¬ä¸­æä¾›çš„ä½†æœªè¯´å‡ºçš„å­—è¯ã€‚æ­¤ç±»å‹æ¥è‡ª SDK è¿”å›çš„å‚æ•°: "ErrorType"ã€‚">
    é—æ¼
    <span class="badge text-bg-secondary">{omission}</span>
    </button>
    <button type="button" class="btn btn-danger" data-bs-toggle="tooltip" data-bs-placement="top" data-bs-title="ä¸åœ¨è„šæœ¬ä¸­ä½†åœ¨å½•åˆ¶ä¸­æ£€æµ‹åˆ°çš„å­—è¯ã€‚æ­¤ç±»å‹æ¥è‡ª SDK è¿”å›çš„å‚æ•°: "ErrorType"ã€‚">
    æ’å…¥å†…å®¹
    <span class="badge text-bg-danger">{insertion}</span>
    </button>
    """


def practice(i, text):
    col1, col2, col3, col4, _ = st.columns([1, 1, 1, 1, 8])
    s_col1, _ = st.columns([4, 8])
    with col1:
        listen_btn = st.button("ğŸ‘‚è†å¬", key="listen_{}".format(i), help="ç‚¹å‡»è†å¬æ–‡æœ¬")
    with col2:
        speak_btn = st.button(
            "ğŸ”Šæœ—è¯»", key="speak_{}".format(i), help="ç‚¹å‡»è·Ÿè¯»æ–‡æœ¬ï¼ŒğŸ‘ˆå·¦ä¾§èœå•æ»‘å—å¯è®¾å®šå½•åˆ¶æ—¶é•¿"
        )
        # if speak_btn:
        #     wav = record_audio(max_duration)
        #     if len(st.session_state["spoken_list"]) == i + 1:
        #         # æ›¿ä»£
        #         st.session_state["spoken_list"][i] = wav
        #     else:
        #         st.session_state["spoken_list"].append(wav)
    with col3:
        replay_btn = st.button("ğŸ§å›æ”¾", key="replay_{}".format(i), help="å›æ”¾è·Ÿè¯»éŸ³é¢‘")
    with col4:
        evaluation_btn = st.button("ğŸ¼è¯„ä¼°", key="evaluation_{}".format(i), help="è¯­éŸ³è¯„ä¼°")

    st.markdown(text)

    with s_col1:
        if listen_btn:
            st.audio(tts_mav_file(text))
        if replay_btn:
            if len(st.session_state["spoken_list"]) >= i + 1:
                st.audio(st.session_state["spoken_list"][i])
            else:
                st.warning("å½•åˆ¶éŸ³é¢‘åæ‰èƒ½å›æ”¾", icon="âš ï¸")

    st.divider()
    container = st.container()
    if evaluation_btn:
        result = pafm(text)
        # st.write(result)
        with container:
            if result["warning"]:
                st.warning(result["warning"], icon="âš ï¸")
            elif result["error"]:
                st.error(result["error"], icon="ğŸš¨")
            else:
                info = result["final_words"]["counter_info"]
                components.html(
                    """
                    <head>
                    <meta charset="utf-8">
                    <meta name="viewport" content="width=device-width, initial-scale=1">
                    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
                    </head>{}""".format(
                        gen_badge(
                            info["mispronunciation"],
                            info["omission"],
                            info["insertion"],
                        )
                    ),
                    height=50,
                )
                annotated_text(
                    *[annotation(**tag) for tag in result["final_words"]["tags"]]
                )

                col1, col2, col3, col4 = st.columns(4)
                last_score = st.session_state["assessment_score"][-1]
                col1.metric(
                    "å‘éŸ³åˆ†æ•°",
                    "{:.2f}".format(result["scores"]["pronunciation"]),
                    "{:.2f}".format(
                        result["scores"]["pronunciation"] - last_score["pronunciation"]
                    ),
                    help="è¡¨ç¤ºç»™å®šè¯­éŸ³å‘éŸ³è´¨é‡çš„æ€»ä½“åˆ†æ•°ã€‚å®ƒæ˜¯ä» AccuracyScoreã€FluencyScoreã€CompletenessScoreã€Weight æŒ‰æƒé‡èšåˆçš„ã€‚",
                )
                col2.metric(
                    "å‡†ç¡®æ€§è¯„åˆ†",
                    "{:.2f}".format(result["scores"]["accuracy"]),
                    "{:.2f}".format(
                        result["scores"]["accuracy"] - last_score["accuracy"]
                    ),
                    help="è¯­éŸ³çš„å‘éŸ³å‡†ç¡®æ€§ã€‚å‡†ç¡®æ€§è¡¨ç¤ºéŸ³ç´ ä¸æ¯è¯­è¯´è¯äººçš„å‘éŸ³çš„åŒ¹é…ç¨‹åº¦ã€‚å­—è¯å’Œå…¨æ–‡çš„å‡†ç¡®æ€§å¾—åˆ†æ˜¯ç”±éŸ³ç´ çº§çš„å‡†ç¡®åº¦å¾—åˆ†æ±‡æ€»è€Œæ¥ã€‚",
                )
                col3.metric(
                    "æµç•…æ€§è¯„åˆ†",
                    "{:.2f}".format(result["scores"]["fluency"]),
                    "{:.2f}".format(
                        result["scores"]["fluency"] - last_score["fluency"]
                    ),
                    help="ç»™å®šè¯­éŸ³çš„æµç•…æ€§ã€‚æµç•…æ€§è¡¨ç¤ºè¯­éŸ³ä¸æ¯è¯­è¯´è¯äººåœ¨å•è¯é—´çš„åœé¡¿ä¸Šæœ‰å¤šæ¥è¿‘ã€‚",
                )
                col4.metric(
                    "å®Œæ•´æ€§è¯„åˆ†",
                    "{:.2f}".format(result["scores"]["completeness"]),
                    "{:.2f}".format(
                        result["scores"]["completeness"] - last_score["completeness"]
                    ),
                    help="è¯­éŸ³çš„å®Œæ•´æ€§ï¼ŒæŒ‰å‘éŸ³å•è¯ä¸è¾“å…¥å¼•ç”¨æ–‡æœ¬çš„æ¯”ç‡è®¡ç®—ã€‚",
                )
        # è®°å½•å¾—åˆ†
        st.session_state["assessment_score"].append(result["scores"])
    st.divider()


# ä¸´æ—¶æµ‹è¯•
if "scenario" not in st.session_state:
    st.session_state[
        "scenario"
    ] = """For users who have already developed prompts and flows using the open-source library, such as LangChain, prompt flow provides a seamless integration pathway. 
    This compatibility enables you to lift and shift your existing assets to prompt flow, facilitating Prompt Engineering, evaluation, and collaboration efforts to prepare your flow for production. 
    This smooth transition ensures that your previous work is not lost and can be further enhanced within the prompt flow environment for evaluation, optimization and production."""

if st.session_state["scenario"]:
    sentences = [l for l in st.session_state["scenario"].splitlines() if l]
    # æŒ‰è¡Œåˆ†å‰²ï¼Œå»é™¤ç©ºè¡Œ
    for i, line in enumerate(sentences):
        practice(i, line)
