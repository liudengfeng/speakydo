import streamlit as st
import streamlit.components.v1 as components
from pylib.cognitive import (
    # speech_recognize_once_from_mic,
    speech_synthesis_to_file,
    # record_audio,
    pronunciation_assessment_from_microphone,
)
from pylib.constants import TTS_VOICES
from pathlib import Path
from annotated_text import annotated_text, annotation

# --- PATH SETTINGS ---
current_dir: Path = Path(__file__).parent.parent

voice_path: Path = current_dir / "static/audio"

st.set_page_config(
    page_title="å£è¯­ç»ƒä¹ ",
    page_icon="ğŸ—£ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ç»ƒä¹ å£è¯­å†å²è®°å½•
if "spoken_list" not in st.session_state:
    st.session_state["spoken_list"] = []

# å‘éŸ³è¯„ä¼°å¾—åˆ†
if "assessment_score" not in st.session_state:
    st.session_state["assessment_score"] = [
        {"pronunciation": 0, "accuracy": 0, "fluency": 0, "completeness": 0}
    ]

# ä¾§é¢èœå•æ³¨é‡Š
st.sidebar.subheader(st.session_state.native_language.oral_practice_label)

voice_options = [
    item[0] for item in TTS_VOICES[st.session_state.target_language.language_key]
]


def get_index(voice):
    names = [
        item[0] for item in TTS_VOICES[st.session_state.target_language.language_key]
    ]
    return names.index(voice)


def voice_format_func(voice):
    i = get_index(voice)
    return TTS_VOICES[st.session_state.target_language.language_key][i][1]


st.sidebar.selectbox(
    st.session_state.native_language.selectbox_voice_name_label,
    voice_options,
    format_func=voice_format_func,
    key="voice_name",
    # label_visibility="hidden",
)


voice_file = voice_path / "{}.wav".format(st.session_state["voice_name"])
st.sidebar.audio(str(voice_file))


@st.cache_data(show_spinner="Speech synthesis from Azure AI...")
def tts_mav_file(text):
    return speech_synthesis_to_file(
        text,
        st.session_state["voice_name"],
        st.secrets.Microsoft.SPEECH_KEY,
        st.secrets.Microsoft.SPEECH_REGION,
    )


def pafm(text):
    return pronunciation_assessment_from_microphone(
        text,
        st.secrets.Microsoft.SPEECH_KEY,
        st.secrets.Microsoft.SPEECH_REGION,
        st.session_state.target_language.language_key,
    )


def gen_badge(mispronunciation, omission, insertion):
    return f"""
    <button type="button" class="btn btn-warning" data-bs-toggle="tooltip" data-bs-placement="top" data-bs-title="è¯´å¾—ä¸æ­£ç¡®çš„å­—è¯ã€‚æ­¤ç±»å‹æ¥è‡ª SDK è¿”å›çš„å‚æ•°: "ErrorType"ã€‚">
    å‘éŸ³é”™è¯¯
    <span class="badge text-bg-warning">{mispronunciation}</span>
    </button>
    <button type="button" class="btn btn-secondary" data-bs-toggle="tooltip" data-bs-placement="top" data-bs-title="è„šæœ¬ä¸­æä¾›çš„ä½†æœªè¯´å‡ºçš„å­—è¯ã€‚æ­¤ç±»å‹æ¥è‡ª SDK è¿”å›çš„å‚æ•°: "ErrorType"ã€‚">
    é—æ¼
    <span class="badge text-bg-secondary">{omission}</span>
    </button>
    <button type="button" class="btn btn-danger" data-bs-toggle="tooltip" data-bs-placement="top" data-bs-title="ä¸åœ¨è„šæœ¬ä¸­ä½†åœ¨å½•åˆ¶ä¸­æ£€æµ‹åˆ°çš„å­—è¯ã€‚æ­¤ç±»å‹æ¥è‡ª SDK è¿”å›çš„å‚æ•°: "ErrorType"ã€‚">
    æ’å…¥å†…å®¹
    <span class="badge text-bg-danger">{insertion}</span>
    </button>
    """


def practice(i, text):
    btn_col1, btn_col2, _ = st.columns([1, 1, 10])
    with btn_col1:
        listen_btn = st.button("ğŸ‘‚è†å¬", key="listen_{}".format(i), help="ç‚¹å‡»è†å¬æ–‡æœ¬")

    with btn_col2:
        evaluation_btn = st.button("ğŸ¼è¯„ä¼°", key="evaluation_{}".format(i), help="è¯­éŸ³è¯„ä¼°")

    st.markdown(text)

    if listen_btn:
        s_col1, _ = st.columns([4, 8])
        with s_col1:
            st.audio(tts_mav_file(text))

    st.divider()
    container = st.container()

    if evaluation_btn:
        result = pafm(text)
        # st.write(result)
        with container:
            if result["warning"]:
                st.warning(result["warning"], icon="âš ï¸")
            elif result["error"]:
                st.error(result["error"], icon="ğŸš¨")
            else:
                info = result["final_words"]["counter_info"]
                components.html(
                    """
                    <head>
                    <meta charset="utf-8">
                    <meta name="viewport" content="width=device-width, initial-scale=1">
                    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
                    </head>{}""".format(
                        gen_badge(
                            info["mispronunciation"],
                            info["omission"],
                            info["insertion"],
                        )
                    ),
                    height=50,
                )
                annotated_text(
                    *[annotation(**tag) for tag in result["final_words"]["tags"]]
                )

                col1, col2, col3, col4 = st.columns(4)
                last_score = st.session_state["assessment_score"][-1]
                col1.metric(
                    "å‘éŸ³åˆ†æ•°",
                    "{:.2f}".format(result["scores"]["pronunciation"]),
                    "{:.2f}".format(
                        result["scores"]["pronunciation"] - last_score["pronunciation"]
                    ),
                    help="è¡¨ç¤ºç»™å®šè¯­éŸ³å‘éŸ³è´¨é‡çš„æ€»ä½“åˆ†æ•°ã€‚å®ƒæ˜¯ä» AccuracyScoreã€FluencyScoreã€CompletenessScoreã€Weight æŒ‰æƒé‡èšåˆçš„ã€‚",
                )
                col2.metric(
                    "å‡†ç¡®æ€§è¯„åˆ†",
                    "{:.2f}".format(result["scores"]["accuracy"]),
                    "{:.2f}".format(
                        result["scores"]["accuracy"] - last_score["accuracy"]
                    ),
                    help="è¯­éŸ³çš„å‘éŸ³å‡†ç¡®æ€§ã€‚å‡†ç¡®æ€§è¡¨ç¤ºéŸ³ç´ ä¸æ¯è¯­è¯´è¯äººçš„å‘éŸ³çš„åŒ¹é…ç¨‹åº¦ã€‚å­—è¯å’Œå…¨æ–‡çš„å‡†ç¡®æ€§å¾—åˆ†æ˜¯ç”±éŸ³ç´ çº§çš„å‡†ç¡®åº¦å¾—åˆ†æ±‡æ€»è€Œæ¥ã€‚",
                )
                col3.metric(
                    "æµç•…æ€§è¯„åˆ†",
                    "{:.2f}".format(result["scores"]["fluency"]),
                    "{:.2f}".format(
                        result["scores"]["fluency"] - last_score["fluency"]
                    ),
                    help="ç»™å®šè¯­éŸ³çš„æµç•…æ€§ã€‚æµç•…æ€§è¡¨ç¤ºè¯­éŸ³ä¸æ¯è¯­è¯´è¯äººåœ¨å•è¯é—´çš„åœé¡¿ä¸Šæœ‰å¤šæ¥è¿‘ã€‚",
                )
                col4.metric(
                    "å®Œæ•´æ€§è¯„åˆ†",
                    "{:.2f}".format(result["scores"]["completeness"]),
                    "{:.2f}".format(
                        result["scores"]["completeness"] - last_score["completeness"]
                    ),
                    help="è¯­éŸ³çš„å®Œæ•´æ€§ï¼ŒæŒ‰å‘éŸ³å•è¯ä¸è¾“å…¥å¼•ç”¨æ–‡æœ¬çš„æ¯”ç‡è®¡ç®—ã€‚",
                )
        # è®°å½•å¾—åˆ†
        st.session_state["assessment_score"].append(result["scores"])
    st.divider()


# # ä¸´æ—¶æµ‹è¯•
# if "scenario" not in st.session_state:
#     st.session_state[
#         "scenario"
#     ] = """For users who have already developed prompts and flows using the open-source library, such as LangChain, prompt flow provides a seamless integration pathway.
#     This compatibility enables you to lift and shift your existing assets to prompt flow, facilitating Prompt Engineering, evaluation, and collaboration efforts to prepare your flow for production.
#     This smooth transition ensures that your previous work is not lost and can be further enhanced within the prompt flow environment for evaluation, optimization and production."""

if st.session_state["scenario"]:
    sentences = [l for l in st.session_state["scenario"].splitlines() if l]
    # æŒ‰è¡Œåˆ†å‰²ï¼Œå»é™¤ç©ºè¡Œ
    for i, line in enumerate(sentences):
        practice(i, line)
